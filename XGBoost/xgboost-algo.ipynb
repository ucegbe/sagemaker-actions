{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbbb2e4a-3a61-45c7-a69a-008b2fa934e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.11/site-packages (2.241.0)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (23.2.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.35.75 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (1.37.9)\n",
      "Requirement already satisfied: cloudpickle>=2.2.1 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: docker in /opt/conda/lib/python3.11/site-packages (from sagemaker) (7.1.0)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.11/site-packages (from sagemaker) (0.115.8)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.11/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (6.10.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.11/site-packages (from sagemaker) (4.23.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (1.26.4)\n",
      "Requirement already satisfied: omegaconf<=2.3,>=2.2 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (24.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from sagemaker) (2.2.3)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.11/site-packages (from sagemaker) (0.3.3)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from sagemaker) (4.3.6)\n",
      "Requirement already satisfied: protobuf<6.0,>=3.12 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (4.25.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from sagemaker) (5.9.8)\n",
      "Requirement already satisfied: pyyaml~=6.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from sagemaker) (2.32.3)\n",
      "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.17 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (1.0.25)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.11/site-packages (from sagemaker) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (2.0.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from sagemaker) (4.67.1)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /opt/conda/lib/python3.11/site-packages (from sagemaker) (1.26.19)\n",
      "Requirement already satisfied: uvicorn in /opt/conda/lib/python3.11/site-packages (from sagemaker) (0.34.0)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.9 in /opt/conda/lib/python3.11/site-packages (from boto3<2.0,>=1.35.75->sagemaker) (1.37.9)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3<2.0,>=1.35.75->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /opt/conda/lib/python3.11/site-packages (from boto3<2.0,>=1.35.75->sagemaker) (0.11.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.21.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/conda/lib/python3.11/site-packages (from omegaconf<=2.3,>=2.2->sagemaker) (4.9.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.10.6)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.0.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (13.9.4)\n",
      "Requirement already satisfied: mock<5.0,>4.0 in /opt/conda/lib/python3.11/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (4.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema->sagemaker) (0.22.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->sagemaker) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->sagemaker) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->sagemaker) (2024.12.14)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /opt/conda/lib/python3.11/site-packages (from fastapi->sagemaker) (0.45.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from fastapi->sagemaker) (4.12.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from google-pasta->sagemaker) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->sagemaker) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->sagemaker) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->sagemaker) (2025.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.9 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker) (1.7.6.9)\n",
      "Requirement already satisfied: dill>=0.3.9 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker) (0.3.9)\n",
      "Requirement already satisfied: pox>=0.3.5 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker) (0.3.5)\n",
      "Requirement already satisfied: multiprocess>=0.70.17 in /opt/conda/lib/python3.11/site-packages (from pathos->sagemaker) (0.70.17)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.11/site-packages (from uvicorn->sagemaker) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.11/site-packages (from uvicorn->sagemaker) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.27.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.19.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /opt/conda/lib/python3.11/site-packages (from starlette<0.46.0,>=0.40.0->fastapi->sagemaker) (4.8.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi->sagemaker) (1.3.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sagemaker -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b8a9bbe-127d-418d-bbde-817c8178777f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sagemaker.Session().boto_region_name\n",
    "session = Session()\n",
    "from IPython.display import display\n",
    "from time import strftime, gmtime\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sklearn import preprocessing\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = \"sagemaker/DEMO-xgboost-dist-algo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32eb499-7b2c-4031-98a5-bdd7306f1d8c",
   "metadata": {},
   "source": [
    "## 2. Data Preparation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bce6c2d-f4e7-4a6a-8241-58568a280ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/20/25 17:48:08] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Skipping checksum validation. Response did not contain one of the  <a href=\"file:///opt/conda/lib/python3.11/site-packages/botocore/httpchecksum.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">httpchecksum.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/conda/lib/python3.11/site-packages/botocore/httpchecksum.py#481\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">481</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         following algorithms: <span style=\"font-weight: bold\">[</span><span style=\"color: #008700; text-decoration-color: #008700\">'crc32'</span>, <span style=\"color: #008700; text-decoration-color: #008700\">'sha1'</span>, <span style=\"color: #008700; text-decoration-color: #008700\">'sha256'</span><span style=\"font-weight: bold\">]</span>.                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/20/25 17:48:08]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Skipping checksum validation. Response did not contain one of the  \u001b]8;id=340329;file:///opt/conda/lib/python3.11/site-packages/botocore/httpchecksum.py\u001b\\\u001b[2mhttpchecksum.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=443254;file:///opt/conda/lib/python3.11/site-packages/botocore/httpchecksum.py#481\u001b\\\u001b[2m481\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         following algorithms: \u001b[1m[\u001b[0m\u001b[38;2;0;135;0m'crc32'\u001b[0m, \u001b[38;2;0;135;0m'sha1'\u001b[0m, \u001b[38;2;0;135;0m'sha256'\u001b[0m\u001b[1m]\u001b[0m.                 \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "s3.download_file(\n",
    "    f\"sagemaker-example-files-prod-{region}\",\n",
    "    \"datasets/tabular/synthetic/churn.txt\",\n",
    "    \"churn.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccbab731-209a-4088-beb7-0e8f75c31f09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account Length</th>\n",
       "      <th>Area Code</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Int'l Plan</th>\n",
       "      <th>VMail Plan</th>\n",
       "      <th>VMail Message</th>\n",
       "      <th>Day Mins</th>\n",
       "      <th>Day Calls</th>\n",
       "      <th>Day Charge</th>\n",
       "      <th>Eve Mins</th>\n",
       "      <th>Eve Calls</th>\n",
       "      <th>Eve Charge</th>\n",
       "      <th>Night Mins</th>\n",
       "      <th>Night Calls</th>\n",
       "      <th>Night Charge</th>\n",
       "      <th>Intl Mins</th>\n",
       "      <th>Intl Calls</th>\n",
       "      <th>Intl Charge</th>\n",
       "      <th>CustServ Calls</th>\n",
       "      <th>Churn?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PA</td>\n",
       "      <td>163</td>\n",
       "      <td>806</td>\n",
       "      <td>403-2562</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>300</td>\n",
       "      <td>8.162204</td>\n",
       "      <td>3</td>\n",
       "      <td>7.579174</td>\n",
       "      <td>3.933035</td>\n",
       "      <td>4</td>\n",
       "      <td>6.508639</td>\n",
       "      <td>4.065759</td>\n",
       "      <td>100</td>\n",
       "      <td>5.111624</td>\n",
       "      <td>4.928160</td>\n",
       "      <td>6</td>\n",
       "      <td>5.673203</td>\n",
       "      <td>3</td>\n",
       "      <td>True.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC</td>\n",
       "      <td>15</td>\n",
       "      <td>836</td>\n",
       "      <td>158-8416</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>10.018993</td>\n",
       "      <td>4</td>\n",
       "      <td>4.226289</td>\n",
       "      <td>2.325005</td>\n",
       "      <td>0</td>\n",
       "      <td>9.972592</td>\n",
       "      <td>7.141040</td>\n",
       "      <td>200</td>\n",
       "      <td>6.436188</td>\n",
       "      <td>3.221748</td>\n",
       "      <td>6</td>\n",
       "      <td>2.559749</td>\n",
       "      <td>8</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MO</td>\n",
       "      <td>131</td>\n",
       "      <td>777</td>\n",
       "      <td>896-6253</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>300</td>\n",
       "      <td>4.708490</td>\n",
       "      <td>3</td>\n",
       "      <td>4.768160</td>\n",
       "      <td>4.537466</td>\n",
       "      <td>3</td>\n",
       "      <td>4.566715</td>\n",
       "      <td>5.363235</td>\n",
       "      <td>100</td>\n",
       "      <td>5.142451</td>\n",
       "      <td>7.139023</td>\n",
       "      <td>2</td>\n",
       "      <td>6.254157</td>\n",
       "      <td>4</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WY</td>\n",
       "      <td>75</td>\n",
       "      <td>878</td>\n",
       "      <td>817-5729</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>700</td>\n",
       "      <td>1.268734</td>\n",
       "      <td>3</td>\n",
       "      <td>2.567642</td>\n",
       "      <td>2.528748</td>\n",
       "      <td>5</td>\n",
       "      <td>2.333624</td>\n",
       "      <td>3.773586</td>\n",
       "      <td>450</td>\n",
       "      <td>3.814413</td>\n",
       "      <td>2.245779</td>\n",
       "      <td>6</td>\n",
       "      <td>1.080692</td>\n",
       "      <td>6</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WY</td>\n",
       "      <td>146</td>\n",
       "      <td>878</td>\n",
       "      <td>450-4942</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>2.696177</td>\n",
       "      <td>3</td>\n",
       "      <td>5.908916</td>\n",
       "      <td>6.015337</td>\n",
       "      <td>3</td>\n",
       "      <td>3.670408</td>\n",
       "      <td>3.751673</td>\n",
       "      <td>250</td>\n",
       "      <td>2.796812</td>\n",
       "      <td>6.905545</td>\n",
       "      <td>4</td>\n",
       "      <td>7.134343</td>\n",
       "      <td>6</td>\n",
       "      <td>True.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  Account Length  Area Code     Phone Int'l Plan VMail Plan  \\\n",
       "0    PA             163        806  403-2562         no        yes   \n",
       "1    SC              15        836  158-8416        yes         no   \n",
       "2    MO             131        777  896-6253         no        yes   \n",
       "3    WY              75        878  817-5729        yes        yes   \n",
       "4    WY             146        878  450-4942        yes         no   \n",
       "\n",
       "   VMail Message   Day Mins  Day Calls  Day Charge  Eve Mins  Eve Calls  \\\n",
       "0            300   8.162204          3    7.579174  3.933035          4   \n",
       "1              0  10.018993          4    4.226289  2.325005          0   \n",
       "2            300   4.708490          3    4.768160  4.537466          3   \n",
       "3            700   1.268734          3    2.567642  2.528748          5   \n",
       "4              0   2.696177          3    5.908916  6.015337          3   \n",
       "\n",
       "   Eve Charge  Night Mins  Night Calls  Night Charge  Intl Mins  Intl Calls  \\\n",
       "0    6.508639    4.065759          100      5.111624   4.928160           6   \n",
       "1    9.972592    7.141040          200      6.436188   3.221748           6   \n",
       "2    4.566715    5.363235          100      5.142451   7.139023           2   \n",
       "3    2.333624    3.773586          450      3.814413   2.245779           6   \n",
       "4    3.670408    3.751673          250      2.796812   6.905545           4   \n",
       "\n",
       "   Intl Charge  CustServ Calls  Churn?  \n",
       "0     5.673203               3   True.  \n",
       "1     2.559749               8  False.  \n",
       "2     6.254157               4  False.  \n",
       "3     1.080692               6  False.  \n",
       "4     7.134343               6   True.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "churn = pd.read_csv(\"./churn.txt\")\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "churn.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c38e0f1-3c20-434a-96f0-15eeb4e99515",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "churn = pd.concat([churn]*5000, ignore_index=True) # to increase the size of the table for the purpose of increasing the training data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdc23c38-7abc-4279-bca6-e48c397db0c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81c4a50a-697c-42b0-9ca0-597fcc940fc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# churn.to_parquet('train.parquet', index=False)\n",
    "\n",
    "# val.to_parquet('validation.parquet')\n",
    "# test.to_parquet('test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c08d75ce-78a6-44bd-9064-3c3f90d01d30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "churn = churn.drop(\"Phone\", axis=1)\n",
    "churn[\"Area Code\"] = churn[\"Area Code\"].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a75a9bf-a5bd-4c11-888a-d1472086d610",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "churn[\"target\"] = churn[\"Churn?\"].map({\"True.\": 1, \"False.\": 0})\n",
    "churn.drop([\"Churn?\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c091253-9b67-4b69-9c18-8b64d8209e4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "churn = churn[[\"target\"] + churn.columns.tolist()[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31d0e35e-8aef-4346-8683-b600fcf527df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One Hot Encode Cat Variables\n",
    "churn=pd.get_dummies(churn, dtype=int)\n",
    "# churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "312ea9d4-3107-4bee-86dc-6a5622d1b37f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val_n_test = train_test_split(\n",
    "    churn, test_size=0.3, random_state=42, stratify=churn[\"target\"]\n",
    ")\n",
    "\n",
    "val, test = train_test_split(\n",
    "    val_n_test, test_size=0.3, random_state=42, stratify=val_n_test[\"target\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bb0ba62-467d-436e-88f6-1f8223040b19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.to_csv(\"train.csv\", header=False, index=False)\n",
    "val.to_csv(\"validation.csv\", header=False, index=False)\n",
    "test.to_csv(\"test.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347fc2e4-28ce-4cdd-afe2-a11a33fe52f4",
   "metadata": {},
   "source": [
    "For demonstartion purpose on including multiple files under the training channel, we simply duplicate the training data multiple times as shown below.\n",
    "\n",
    "For the purprose of the training logic implemented that uses `xgboost.rabit()` for distributed training,it is recommended to split training sets into multiple chunks so they can be distributed accross training nodes. However, for single node training, this is not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b13d5131-4ce3-4888-8535-0d010c99c4b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:15<00:00,  1.51s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(10)):\n",
    "    boto3.Session().resource(\"s3\").Bucket(bucket).Object(\n",
    "        os.path.join(prefix, f\"train_xgb_micro_pq/data_{i}.parquet\")\n",
    "    ).upload_file(\"train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23880f4d-90e8-425b-8e0f-35e23a94c118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(\n",
    "    os.path.join(prefix, \"validation_xgb_large_pq/data.parquet\")\n",
    ").upload_file(\"validation.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f21de43f-aec7-4f27-8a40-f9e9d0579e06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(\n",
    "    os.path.join(prefix, \"test_xgb_large_pq/data.parquet\")\n",
    ").upload_file(\"test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca843f8d-93a0-430d-b32d-f1b31f42d449",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('s3://sagemaker-us-east-1-715253196401/sagemaker/DEMO-xgboost-dist-algo/train_xgb_single/',\n",
       " 's3://sagemaker-us-east-1-715253196401/sagemaker/DEMO-xgboost-dist-algo/validation_xgb/')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset_s3_path = f\"s3://{bucket}/{prefix}/train_xgb_single/\"\n",
    "validation_dataset_s3_path = f\"s3://{bucket}/{prefix}/validation_xgb/\"\n",
    "\n",
    "output_prefix = \"xgboost-perf-training\"\n",
    "s3_output_location = f\"s3://{bucket}/{output_prefix}/output_xgb\"\n",
    "training_dataset_s3_path, validation_dataset_s3_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e1c7e1-6cf5-43a8-b154-3c1148c1cafe",
   "metadata": {},
   "source": [
    "## Create an XGBoost training script\n",
    "\n",
    "SageMaker can now run an XGBoost script using the XGBoost estimator. When run on SageMaker, a number of helpful environment variables are available to access properties of the training environment, such as:\n",
    "\n",
    "- `SM_MODEL_DIR`: A string representing the path to the directory to write model artifacts to. Any artifacts saved in this folder are uploaded to S3 for model hosting after the training job completes.\n",
    "- `SM_OUTPUT_DIR`: A string representing the filesystem path to write output artifacts to. Output artifacts may include checkpoints, graphs, and other files to save, not including model artifacts. These artifacts are compressed and uploaded to S3 to the same S3 prefix as the model artifacts.\n",
    "\n",
    "When two input channels, `train` and `validation`, are used in the call to the XGBoost estimator's `fit()` method, the following environment variables are set, following the format `SM_CHANNEL_[channel_name]`:\n",
    "\n",
    "- `SM_CHANNEL_TRAIN`: A string representing the path to the directory containing data in the 'train' channel.\n",
    "- `SM_CHANNEL_VALIDATION`: Same as above, but for the 'validation' channel.\n",
    "\n",
    "A typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model to the `model_dir` so that it can be hosted later. Hyperparameters are passed to your script as arguments and can be retrieved with an `argparse.ArgumentParser` instance. For example, the script that we run in this notebook is provided as the accompanying file (`abalone.py`) and also shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09a7e628-90f0-4f2d-8a63-e0a7eda226aa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m#  Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#  Licensed under the Apache License, Version 2.0 (the \"License\").\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#  You may not use this file except in compliance with the License.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#  A copy of the License is located at\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#      http://www.apache.org/licenses/LICENSE-2.0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#  or in the \"license\" file accompanying this file. This file is distributed\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#  express or implied. See the License for the specific language governing\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m#  permissions and limitations under the License.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_function\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpkl\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mxgboost\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mxgb\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_containers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m entry_point\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_xgboost_container\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m distributed\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_xgboost_container\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata_utils\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m get_dmatrix\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_xgboost_container\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36malgorithm_mode\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m hyperparameter_validation \u001b[34mas\u001b[39;49;00m hpv\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_xgboost_container\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36malgorithm_mode\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m metrics \u001b[34mas\u001b[39;49;00m metrics_mod\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_xgboost_container\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36malgorithm_mode\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m channel_validation \u001b[34mas\u001b[39;49;00m cv\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_xgboost_container\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mconstants\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m sm_env_constants\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mre\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mmatplotlib\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mpyplot\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mplt\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mcollections\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m OrderedDict\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mmlflow\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_xgb_train\u001b[39;49;00m(params, dtrain, evals, num_boost_round, model_dir, is_master):\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[33m\"\"\"Run xgb train on arguments given with rabit initialized.\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m    This is our rabit execution function.\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m    :param args_dict: Argument dictionary used to run xgb.train().\u001b[39;49;00m\n",
      "\u001b[33m    :param is_master: True if current node is master host in distributed training,\u001b[39;49;00m\n",
      "\u001b[33m                        or is running single node training job.\u001b[39;49;00m\n",
      "\u001b[33m                        Note that rabit_run will include this argument.\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    logging.basicConfig(level=logging.INFO) \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    booster = xgb.train(params=params, dtrain=dtrain, evals=evals, num_boost_round=num_boost_round)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m is_master:\u001b[37m\u001b[39;49;00m\n",
      "        model_location = os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mxgboost-model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        booster.save_model(model_location)\u001b[37m\u001b[39;49;00m\n",
      "        logging.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mStored trained model at \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mmodel_location\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    parser = argparse.ArgumentParser()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Hyperparameters are described here.    \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--eta\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--gamma\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--min_child_weight\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--subsample\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--verbosity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--objective\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--num_round\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--tree_method\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m\"\u001b[39;49;00m\u001b[33mauto\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--predictor\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m\"\u001b[39;49;00m\u001b[33mauto\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--grow_policy\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m\"\u001b[39;49;00m\u001b[33mdepthwise\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--max_bin\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m256\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--max_depth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m6\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--max_leaves\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--early_stopping_rounds\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m5\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--csv_weights\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--eval_metric\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Sagemaker specific arguments. Defaults are set in the environment variables.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--output_data_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_OUTPUT_DATA_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--model_dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--validation\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_VALIDATION\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--sm_hosts\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--sm_current_host\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--content_type\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m\"\u001b[39;49;00m\u001b[33mcsv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    args, _ = parser.parse_known_args()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    logging.basicConfig(level=logging.INFO) \u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Get SageMaker host information from runtime environment variables\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    sm_hosts = json.loads(args.sm_hosts)\u001b[37m\u001b[39;49;00m\n",
      "    sm_current_host = args.sm_current_host\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#Only logging from scheduler node\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m sm_current_host == sm_hosts[\u001b[34m0\u001b[39;49;00m]:\u001b[37m\u001b[39;49;00m\n",
      "        ml_arn = os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mMLFLOW_TRACKING_ARN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        mlflow.set_tracking_uri(ml_arn)\u001b[37m\u001b[39;49;00m\n",
      "        mlflow.xgboost.autolog()\u001b[37m\u001b[39;49;00m\n",
      "        mlflow.start_run()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    dtrain = get_dmatrix(args.train, args.content_type, csv_weights = args.csv_weights)\u001b[37m\u001b[39;49;00m\n",
      "    dval = get_dmatrix(args.validation, args.content_type, csv_weights = args.csv_weights)\u001b[37m\u001b[39;49;00m\n",
      "    watchlist = (\u001b[37m\u001b[39;49;00m\n",
      "        [(dtrain, \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), (dval, \u001b[33m\"\u001b[39;49;00m\u001b[33mvalidation\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)] \u001b[34mif\u001b[39;49;00m dval \u001b[35mis\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m \u001b[34melse\u001b[39;49;00m [(dtrain, \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)]\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Get the number of samples in the training dataset\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    train_length = dtrain.num_row()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Get the number of samples in the validation dataset\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    val_length = dval.num_row()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mNumber of samples in training dataset: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtrain_length\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mNumber of samples in validation dataset: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mval_length\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    train_hp = {\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mmax_depth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.max_depth,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33meta\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.eta,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mgamma\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.gamma,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mmin_child_weight\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.min_child_weight,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33msubsample\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.subsample,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mverbosity\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.verbosity,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mobjective\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.objective,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mtree_method\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.tree_method,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mpredictor\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.predictor,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mcsv_weights\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: args.csv_weights,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33meval_metric\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:args.eval_metric\u001b[37m\u001b[39;49;00m\n",
      "    }\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m args.grow_policy == \u001b[33m\"\u001b[39;49;00m\u001b[33mdepthwise\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        train_hp[\u001b[33m\"\u001b[39;49;00m\u001b[33mgrow_policy\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = \u001b[33m\"\u001b[39;49;00m\u001b[33mdepthwise\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        train_hp[\u001b[33m\"\u001b[39;49;00m\u001b[33mmax_depth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = args.max_depth\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m args.grow_policy == \u001b[33m\"\u001b[39;49;00m\u001b[33mlossguide\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        train_hp[\u001b[33m\"\u001b[39;49;00m\u001b[33mgrow_policy\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = \u001b[33m\"\u001b[39;49;00m\u001b[33mlossguide\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        train_hp[\u001b[33m\"\u001b[39;49;00m\u001b[33mmax_leaves\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = args.max_leaves  \u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    xgb_train_args = \u001b[36mdict\u001b[39;49;00m(\u001b[37m\u001b[39;49;00m\n",
      "        params=train_hp,\u001b[37m\u001b[39;49;00m\n",
      "        dtrain=dtrain,\u001b[37m\u001b[39;49;00m\n",
      "        evals=watchlist,\u001b[37m\u001b[39;49;00m\n",
      "        num_boost_round=args.num_round,\u001b[37m\u001b[39;49;00m\n",
      "        model_dir=args.model_dir,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(sm_hosts) > \u001b[34m1\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Wait until all hosts are able to find each other\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        entry_point._wait_hostname_resolution()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Execute training function after initializing rabit.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        distributed.rabit_run(\u001b[37m\u001b[39;49;00m\n",
      "            exec_fun=_xgb_train,\u001b[37m\u001b[39;49;00m\n",
      "            args=xgb_train_args,\u001b[37m\u001b[39;49;00m\n",
      "            include_in_training=(dtrain \u001b[35mis\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "            hosts=sm_hosts,\u001b[37m\u001b[39;49;00m\n",
      "            current_host=sm_current_host,\u001b[37m\u001b[39;49;00m\n",
      "            update_rabit_args=\u001b[34mTrue\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        )\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# If single node training, call training method directly.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m dtrain:\u001b[37m\u001b[39;49;00m\n",
      "            xgb_train_args[\u001b[33m\"\u001b[39;49;00m\u001b[33mis_master\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = \u001b[34mTrue\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            _xgb_train(**xgb_train_args)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mraise\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mTraining channel must have data to train model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Only logging from scheduler node\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m sm_current_host == sm_hosts[\u001b[34m0\u001b[39;49;00m]:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# logging number of nodes used for training\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        mlflow.log_params({\u001b[33m\"\u001b[39;49;00m\u001b[33minstance_size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[36mlen\u001b[39;49;00m(sm_hosts)})\u001b[37m\u001b[39;49;00m\n",
      "        mlflow.end_run()\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize -g code/abalone.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aec2d1a-0ccd-491d-b09e-8e92d617e838",
   "metadata": {},
   "source": [
    "Because the container imports your training script, always put your training code in a main guard `(if __name__=='__main__':)` so that the container does not inadvertently run your training code at the wrong point in execution.\n",
    "\n",
    "For more information about training environment variables, please visit the [SageMaker Training Toolkit](https://github.com/aws/sagemaker-training-toolkit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "76dea9a1-2474-4090-a05f-a1e5a50c1c69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.m5.xlarge\"\n",
    "output_path = \"s3://{}/{}/{}/output\".format(bucket, prefix, \"algo-dist-xgb\")\n",
    "content_type =\"csv\" #dataset extension\n",
    "hyperparams = {\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"subsample\": \"0.7\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"num_round\": \"50\",\n",
    "    \"verbosity\": \"3\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"content_type\": content_type,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9129cb-6047-44f6-aa94-c1f5a5ecbba7",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Train the XGBoost model\n",
    "\n",
    "After setting training parameters, we kick off training, and poll for status until training is complete.\n",
    "\n",
    "To run our training script on SageMaker, we construct a sagemaker.xgboost.estimator.XGBoost estimator, which accepts several constructor arguments:\n",
    "\n",
    "* __entry_point__: The path to the Python script that SageMaker runs for training and prediction.\n",
    "* __role__: Role ARN\n",
    "* __train_instance_type__ *(optional)*: The type of SageMaker instances for training.\n",
    "* __sagemaker_session__ *(optional)*: The session used to train on SageMaker.\n",
    "* __hyperparameters__ *(optional)*: A dictionary passed to the train function as hyperparameters.\n",
    "\n",
    "SageMaker Training Directory Setup for Script Mode:\n",
    "\n",
    "- Create a root project directory.\n",
    "- Place main training script (e.g., train.py) in root.\n",
    "- Add other Python modules/scripts to root or subdirectories.\n",
    "- Include requirements.txt for dependencies. Sagemaker automatically installs all libs listed in this text file\n",
    "\n",
    "Example structure:\n",
    "```\n",
    "project/\n",
    "    ├── train.py\n",
    "    ├── requirements.txt\n",
    "    ├── utils.py\n",
    "```\n",
    "\n",
    "SageMaker estimator setup:\n",
    "```\n",
    "estimator = Estimator(\n",
    "    entry_point='train.py',\n",
    "    source_dir='path/to/project',\n",
    "    ...\n",
    ")\n",
    "```\n",
    "Key points:\n",
    "\n",
    "    Include all necessary code files.\n",
    "    List dependencies in requirements.txt.\n",
    "    SageMaker packages entire directory content.    \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5c1235-89b5-4296-8aa5-890b11c1e869",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open Source distributed script mode\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "session = Session()\n",
    "script_path = \"abalone.py\"\n",
    "instance_count = 2 # for distributed training, set instance greater than 1\n",
    "\n",
    "# Your MLflow tracking ARN\n",
    "tracking_server_arn = \"arn:aws:sagemaker:us-east-1:1234567890:mlflow-tracking-server/test\"\n",
    "\n",
    "xgb_script_mode_estimator = XGBoost(\n",
    "    source_dir=\"code\", # parent folder of training logic and dependencies\n",
    "    entry_point=script_path, # training logic path\n",
    "    framework_version=\"1.7-1\",  # Note: framework_version is mandatory\n",
    "    hyperparameters=hyperparams,\n",
    "    role=role,\n",
    "    volume_size=50,\n",
    "    instance_count=instance_count, # for distributed training, set instance greater than 1\n",
    "    instance_type=instance_type,\n",
    "    output_path=output_path,\n",
    "      environment={\"MLFLOW_TRACKING_ARN\": tracking_server_arn},\n",
    "        keep_alive_period_in_seconds = 1000 # Keep instance warm to negate cold start for fast experimentation trials. Charge is incurred for warm instances\n",
    ")\n",
    "\n",
    "train_input = TrainingInput(\n",
    "   training_dataset_s3_path,  content_type=\"text/csv\", distribution = \"ShardedByS3Key\" if instance_count>1 else \"FullyReplicated\"\n",
    ")\n",
    "validation_input = TrainingInput(\n",
    "    validation_dataset_s3_path, content_type=\"text/csv\"\n",
    ")\n",
    "xgb_script_mode_estimator.fit({\"train\": train_input,\n",
    "                               \"validation\": validation_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652da08e-4de0-4f2c-9d37-462825378ada",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"s3://sagemaker-us-east-1-715253196401/sagemaker/DEMO-churn-dt/train2/data_106.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a12b63b-6f19-4439-a8b2-80609237d157",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.84"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.04*96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ae0028-e9e8-4c0d-bedd-c0f5faa72951",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sagemaker.Session().boto_region_name\n",
    "session = Session()\n",
    "\n",
    "# bucket = \"<Specify S3 Bucket>\"\n",
    "# prefix = \"<Specify S3 prefix>\"\n",
    "output_path = \"s3://{}/{}/{}/output\".format(bucket, prefix, \"algo-dist-xgb\")\n",
    "hyperparams = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"num_round\": \"500\",\n",
    "    \"verbosity\": \"3\",\n",
    "    \"tree_method\": \"gpu_hist\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"use_dask_gpu_training\": \"true\"\n",
    "}\n",
    "\n",
    "\n",
    "# output_path = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "\n",
    "content_type = \"application/x-parquet\"\n",
    "instance_type = \"ml.g5.16xlarge\"\n",
    "\n",
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.7-1\")\n",
    "xgb_script_mode_estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=xgboost_container,\n",
    "    hyperparameters=hyperparams,\n",
    "    role=role,\n",
    "    instance_count=10,\n",
    "    instance_type=instance_type,\n",
    "    output_path=output_path,\n",
    "    max_run=7200,\n",
    "    volume_size=500,\n",
    "    keep_alive_period_in_seconds = 1000\n",
    ")\n",
    "\n",
    "train_input = TrainingInput(\n",
    "    \"s3://sagemaker-us-east-1-715253196401/sagemaker/DEMO-xgboost-dist-algo/train_xgb_micro_pq/\", content_type=content_type\n",
    ")\n",
    "\n",
    "validation_input = TrainingInput(\n",
    "    \"s3://sagemaker-us-east-1-715253196401/sagemaker/DEMO-xgboost-dist-algo/validation_xgb_large_pq/\", content_type=content_type\n",
    ")\n",
    "\n",
    "xgb_script_mode_estimator.fit({\"train\": train_input, \"validation\": validation_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05c6cdd-11e2-4fa7-b346-fcf9767c1dc8",
   "metadata": {},
   "source": [
    "## Deploy the XGBoost model\n",
    "Once the training is done, SageMaker packages your model artifacts along with any dependencies used for training including the `inference,py` which we will use as our inference logic. It is also possible to pass a seperate inference logic if you wish so.\n",
    "After training we deploy the model using the Estimator object and point to our inference script for serving the model. Here we have defined SaegMaker specific functions `model_fn`, `predict_fn` to load and make prediction on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ae377a13-9ffc-4b29-9a3f-b51b1030fccf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2024-10-28-03-37-11-315\n",
      "INFO:sagemaker:Creating endpoint-config with name sagemaker-xgboost-2024-10-28-03-37-11-315\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-xgboost-2024-10-28-03-37-11-315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "predictor = xgb_script_mode_estimator.deploy(\n",
    "    initial_instance_count=1, \n",
    "    instance_type=\"ml.m5.xlarge\", \n",
    "    entry_point=\"inference.py\", # path to inference script within the model package\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "03021596-2ee2-412f-a1c9-dc37e051bed4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load test Data\n",
    "import pandas as pd\n",
    "features=pd.read_csv(\"test.csv\").iloc[:,1:]\n",
    "num_examples=len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "52dfdf06-9c9c-41a8-a78f-ef08e050c10b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content_type = \"text/csv\"\n",
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "predictor.serializer = sagemaker.serializers.CSVSerializer()\n",
    "\n",
    "def query_endpoint(encoded_tabular_data, endpoint_name):\n",
    "    client = boto3.client(\"runtime.sagemaker\")\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType=content_type,\n",
    "        Body=encoded_tabular_data,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "# split the test data into smaller size of batches to query the endpoint if test data has large size.\n",
    "batch_size = 1500\n",
    "predict_prob = []\n",
    "for i in np.arange(0, num_examples, step=batch_size):\n",
    "    payload=features.iloc[i : (i + batch_size), :].to_csv(header=False, index=False).strip()\n",
    "    predict_prob.extend(predictor.predict(payload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e46b52-f45e-4e9c-9cd0-97a9c139f6ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb3d538-e83e-4ffe-8b0a-c2714811c1b6",
   "metadata": {},
   "source": [
    "# Automatic model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90d12b6-bb53-48f2-bab5-6311cf805b31",
   "metadata": {
    "tags": []
   },
   "source": [
    "Amazon SageMaker automatic model tuning, also known as hyperparameter tuning, finds the best version of a model by running many training jobs on your dataset using the algorithm and ranges of hyperparameters that you specify. It then chooses the hyperparameter values that result in a model that performs the best, as measured by a metric that you choose. For example, suppose that you want to solve a binary classification problem on this marketing dataset. Your goal is to maximize the area under the curve (auc) metric of the algorithm by training an XGBoost Algorithm model. You don't know which values of the eta, alpha, min_child_weight, and max_depth hyperparameters to use to train the best model. To find the best values for these hyperparameters, you can specify ranges of values that Amazon SageMaker hyperparameter tuning searches to find the combination of values that results in the training job that performs the best as measured by the objective metric that you chose. Hyperparameter tuning launches training jobs that use hyperparameter values in the ranges that you specified, and returns the training job with highest auc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "365f5ee4-bf8d-403a-aa99-3c386f1cf20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "hyperparameter_ranges = {'eta': ContinuousParameter(0, 1),\n",
    "                            'min_child_weight': ContinuousParameter(1, 10),\n",
    "                            'alpha': ContinuousParameter(0, 2),\n",
    "                            'max_depth': IntegerParameter(1, 10)}\n",
    "\n",
    "objective_metric_name = 'validation:auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "218682eb-cc43-413d-9d41-17bffea334f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating hyperparameter tuning job with name: sagemaker-xgboost-241028-0353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................................................!\n"
     ]
    }
   ],
   "source": [
    "tuner = HyperparameterTuner(xgb_script_mode_estimator,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            max_jobs=6, # maximum number of canditate jobs\n",
    "                            max_parallel_jobs=3) # number of jobs to execute in parallel\n",
    "tuner.fit({'train': train_input, 'validation': validation_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75649df1-eae4-42de-ae22-cae52a513108",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_instance_type = \"ml.m5.xlarge\"\n",
    "\n",
    "# Use the estimator from the previous step to deploy to a SageMaker endpoint\n",
    "predictor = tuner.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    entry_point=\"inference.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "85fd5e3d-9fda-4db0-871c-7f792b9f9f78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load test Data\n",
    "import pandas as pd\n",
    "features=pd.read_csv(\"test.csv\").iloc[:,1:]\n",
    "num_examples=len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a180908a-95b3-4fa6-a382-6344d1f0206e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content_type = \"text/csv\"\n",
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "predictor.serializer = sagemaker.serializers.CSVSerializer()\n",
    "\n",
    "\n",
    "# split the test data into smaller size of batches to query the endpoint if test data has large size.\n",
    "batch_size = 1500\n",
    "predict_prob = []\n",
    "for i in np.arange(0, num_examples, step=batch_size):\n",
    "    payload=features.iloc[i : (i + batch_size), :].to_csv(header=False, index=False).strip()\n",
    "    predict_prob.extend(predictor.predict(payload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba8b96-0b5e-4144-900e-dbbd080b8902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef08e2e3-e98c-46d6-a47a-08742aedb7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.m5.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
